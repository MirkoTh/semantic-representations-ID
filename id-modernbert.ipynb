{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4489279b-cf8c-4a48-a4f6-81b355f37ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to find MSVC.\n",
      "WARNING: Failed to find Windows SDK.\n",
      "WARNING: Failed to find CUDA.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM, BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a1fe8b0-5c36-436d-a515-b0e6a6beefc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from turtle import distance\n",
    "import warnings\n",
    "from adjustText import adjust_text\n",
    "from typing import Tuple, Iterator, List, Dict\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from os.path import join as pjoin\n",
    "from collections import defaultdict\n",
    "from scipy.stats import linregress\n",
    "from torch.optim import Adam, AdamW\n",
    "\n",
    "os.environ['PYTHONIOENCODING']='UTF-8'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']=str(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc6f37-b1fc-4e6d-9c24-a3d9fe87f49a",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- fasttext installation does not work, neither with conda nor with pip\n",
    "- GloVe and Word2Vec can be installed, but several things words not part of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e1f936c-907a-465d-904e-1b4ec582f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable automatic reloading of modules before executing code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# Now you can use wildcard import\n",
    "import plotting as pl\n",
    "from models import model as md\n",
    "import utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "887dba3f-cd4e-4869-8921-f8df56504ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logger\n",
    "logger = logging.getLogger('ooo-modernbert')\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# create console handler and set level to debug\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "\n",
    "# create formatter\n",
    "formatter = logging.Formatter(\n",
    "    fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y/%m/%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# add formatter to ch\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "# add ch to logger\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fc2c702-7563-4358-ad29-a99e9e12ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1356911c-adeb-44f9-9fd8-6db73266036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input1 = tokenizer.encode(\"woman\", return_tensors=\"pt\").to(device)\n",
    "output1 = model(tokenized_input1)\n",
    "e1 = output1.last_hidden_state[0]\n",
    "e1 = torch.mean(e1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fa92ccb-1df1-4847-bae4-a60f0f2fb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input2 = tokenizer.encode(\"man\", return_tensors=\"pt\").to(device)\n",
    "output2 = model(tokenized_input2)\n",
    "e2 = output2.last_hidden_state[0]\n",
    "e2 = torch.mean(e2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a11ddf97-07bf-4ae7-ae5b-dd08ae785568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_input3 = tokenizer.encode(\"headphones\", return_tensors=\"pt\").to(device)\n",
    "output3 = model(tokenized_input3)\n",
    "e3 = output3.last_hidden_state[0]\n",
    "e3 = torch.mean(e3, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c000367-d1e0-49a9-a9f5-38fdd15bd354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(624.7878, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(e1*e2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0754e77-5d1d-47ee-a9d9-b2cfd2dd2ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(531.2306, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(e1*e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ea34916-78c1-4feb-96dc-f1b741ae6eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(556.2291, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(e2*e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67e6c454-bdb7-430b-a74f-b37d046d054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_labels = pd.read_csv(\"data/unique_id.txt\", delimiter=\"\\\\\", header=None)\n",
    "tbl_labels[\"label_id\"] = np.arange(1, tbl_labels.shape[0]+1)\n",
    "tbl_labels.columns = [\"label\", \"label_id\"]\n",
    "new_order = [\"label_id\", \"label\"]\n",
    "tbl_labels = tbl_labels[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aba0d9f3-4be3-4d8e-b44b-26fcd8aa5716",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_embeddings = ut.load_avg_embeddings(\"Word2Vec\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a95d7bb-c078-446f-9050-2e32e0771134",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_embeddings = []\n",
    "for prompt in tbl_labels[\"label\"]:\n",
    "    tokenized_input = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(tokenized_input)\n",
    "    embedding = output.last_hidden_state[0]\n",
    "    emb_flat = torch.mean(embedding, axis=0).detach().numpy()\n",
    "    l_embeddings.append(emb_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da694861-7b47-4dfe-8080-177889c5e33e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_input1 = tokenizer.encode(\"man\", return_tensors=\"pt\").to(device)\n",
    "output1 = model(tokenized_input1)\n",
    "e1 = output1.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0f2e86c-73b1-4f0f-b094-8db864143d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input2 = tokenizer.encode(\"woman\", return_tensors=\"pt\").to(device)\n",
    "output2 = model(tokenized_input2)\n",
    "e2 = output2.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14b5cb96-4a9b-4cb0-9f72-7bb9e86af47e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_input3 = tokenizer.encode(\"forest\", return_tensors=\"pt\").to(device)\n",
    "output3 = model(tokenized_input3)\n",
    "e3 = output3.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d913e538-20e6-49eb-8b75-002242897b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([540.5472], grad_fn=<SumBackward1>),\n",
       " tensor([1202.3362], grad_fn=<SumBackward1>),\n",
       " tensor([483.3616], grad_fn=<SumBackward1>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ut.compute_similarities(e1, e2, e3, method=\"odd_one_out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ce2691-61ef-401e-97e0-9a51bcda81ca",
   "metadata": {},
   "source": [
    "# Setup Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b80d2c86-a715-462f-bca6-831ed8946d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"odd_one_out\"\n",
    "modality = \"behavioral\"\n",
    "triplets_dir = \"./data/\"\n",
    "lr = learning_rate = 0.001\n",
    "lmbda = 0.0005\n",
    "temperature = 1\n",
    "num_threads = 6\n",
    "device = \"cpu\"\n",
    "batch_size = 50\n",
    "sampling_method = \"normal\"\n",
    "rnd_seed = 42\n",
    "p = None\n",
    "results_dir = './results/'\n",
    "plots_dir = './plots/'\n",
    "epochs = 10\n",
    "distance_metric = \"dot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d82b5710-88c8-46da-afe4-1362ad233df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...Could not find any .npy files for current modality.\n",
      "...Now searching for .txt files.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load triplets into memory\n",
    "train_triplets, test_triplets = ut.load_data_ID(device=device, triplets_dir=triplets_dir, testcase = False)\n",
    "n_items = ut.get_nitems(train_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0094800a-82f6-4113-9806-b5e2a1cc0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_participants = len(np.unique(train_triplets.numpy()[:,3]))\n",
    "array_embeddings = np.array(l_embeddings)\n",
    "embed_dim = array_embeddings.shape[1]\n",
    "tensor_avg_reps = torch.Tensor(array_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f94a4aae-93d9-4fab-80b6-9b3282785b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ee96b78-becd-4201-952d-fb51322c7d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1854, 300)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76841a68-c062-428f-b883-e5b0bfc34d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load train and test mini-batches\n",
    "train_batches, val_batches = ut.load_batches_ID(\n",
    "    train_triplets=train_triplets,\n",
    "    test_triplets=test_triplets,\n",
    "    average_reps=tensor_avg_reps,\n",
    "    n_items=n_items,\n",
    "    batch_size=batch_size,\n",
    "    sampling_method=sampling_method,\n",
    "    rnd_seed=rnd_seed,\n",
    "    p=p,\n",
    "    method=\"embedding\",\n",
    "    within_subjects=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f83bc2b-696c-40e5-9ec9-15e85e09a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "lmbda = .01\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e298c0df-3883-4e02-96fe-215fda7c97d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MirkoThalmann\\AppData\\Local\\Temp\\ipykernel_20132\\2647874632.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  temperature = torch.tensor(temperature).clone().detach()\n"
     ]
    }
   ],
   "source": [
    "temperature = torch.tensor(temperature).clone().detach()\n",
    "model_weight = md.Weighted_Embedding(\n",
    "    embed_size=embed_dim,\n",
    "    num_participants=n_participants,\n",
    "    init_weights=True\n",
    ")\n",
    "model_weight.to(device)\n",
    "optim = Adam(model_weight.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "465de757-3562-4081-89d3-0facc91b81c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Creating PATHs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'...Creating PATHs')\n",
    "print()\n",
    "if results_dir == './results/':\n",
    "    results_dir = os.path.join(results_dir, modality, str(lmbda), f'seed{rnd_seed:02d}')\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "if plots_dir == './plots/':\n",
    "    plots_dir = os.path.join(plots_dir, modality, str(lmbda), f'seed{rnd_seed}')\n",
    "if not os.path.exists(plots_dir):\n",
    "    os.makedirs(plots_dir)\n",
    "\n",
    "model_dir = os.path.join(results_dir, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "50325e26-aedc-49bb-826e-7b33b7141eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/03 16:40:58 - ooo-modernbert - INFO - Optimization started for lambda: 0.01\n",
      "\n",
      "2025/02/03 16:40:58 - ooo-modernbert - INFO - Optimization started for lambda: 0.01\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization started for lambda: 0.01\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7845c3e2129442a69f02a76db8333f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "start = 0\n",
    "train_accs, val_accs = [], []\n",
    "train_losses, val_losses = [], []\n",
    "loglikelihoods = []\n",
    "nneg_d_over_time = []\n",
    "\n",
    "iter = 0\n",
    "results = {}\n",
    "logger.info(f'Optimization started for lambda: {lmbda}\\n')\n",
    "\n",
    "print(f'Optimization started for lambda: {lmbda}\\n')\n",
    "for epoch in tqdm(range(start, epochs)):\n",
    "    model_weight.train()\n",
    "    batch_llikelihoods = torch.zeros(len(train_batches))\n",
    "    batch_closses = torch.zeros(len(train_batches))\n",
    "    batch_losses_train = torch.zeros(len(train_batches))\n",
    "    batch_accs_train = torch.zeros(len(train_batches))\n",
    "    for i, batch in enumerate(train_batches):\n",
    "        optim.zero_grad() #zero out gradients\n",
    "        d = batch[0].to(device)\n",
    "        ids = batch[1].to(device)\n",
    "        logits = model_weight(d, ids)\n",
    "        anchor, positive, negative = torch.unbind(torch.reshape(logits, (-1, 3, embed_dim)), dim=1)\n",
    "        tri_loss = ut.trinomial_loss(anchor, positive, negative, task, temperature, distance_metric)\n",
    "        l1_pen_ID = md.l1_regularization(model_weight, \"individual_slopes.weight\", \"few\").to(device) #L1-norm to enforce sparsity (many 0s)\n",
    "        complexity_loss_ID = (lmbda/n_participants) * l1_pen_ID\n",
    "        loss = tri_loss + complexity_loss_ID\n",
    "        \n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        batch_losses_train[i] += loss.item()\n",
    "        batch_llikelihoods[i] += loss.item()\n",
    "        batch_accs_train[i] += ut.choice_accuracy(anchor, positive, negative, task, distance_metric)\n",
    "        iter += 1\n",
    "\n",
    "    avg_llikelihood = torch.mean(batch_llikelihoods).item()\n",
    "    avg_train_loss = torch.mean(batch_losses_train).item()\n",
    "    avg_train_acc = torch.mean(batch_accs_train).item()\n",
    "    \n",
    "    loglikelihoods.append(avg_llikelihood)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accs.append(avg_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "095c05d1-f34c-45ce-8689-4f43566057bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4155126214027405, 0.412482351064682]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45ab3a70-1749-4f56-ae67-a9e5c49a0219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1096850633621216, 1.1079800128936768]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6dffe32-4690-4104-9663-29bd4ce3d8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.090592622756958, 0.4242890775203705)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ut.validation(model_weight, val_batches, task, device, level_explanation=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4da281a4-5dbe-4073-ba2d-f1c68cbaed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_llikelihood = torch.mean(batch_llikelihoods).item()\n",
    "avg_train_loss = torch.mean(batch_losses_train).item()\n",
    "avg_train_acc = torch.mean(batch_accs_train).item()\n",
    "\n",
    "loglikelihoods.append(avg_llikelihood)\n",
    "train_losses.append(avg_train_loss)\n",
    "train_accs.append(avg_train_acc)\n",
    "\n",
    "################################################\n",
    "################ validation ####################\n",
    "################################################\n",
    "\n",
    "avg_val_loss, avg_val_acc = ut.validation(\n",
    "    model_weight, val_batches, task, device, level_explanation=\"ID\")\n",
    "val_losses.append(avg_val_loss)\n",
    "val_accs.append(avg_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c302001-ef45-482f-aa34-adf4be262421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1451358795166016"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0799ef67-a3f6-4d00-95f2-3502b1cd9810",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"results\\ID-on-embeddings\\answerdotai\\ModernBERT-based\\0.001\\few\\seed549\\model\\model_epoch0002.tar\"\n",
    "\n",
    "os.path.isfile(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3386b69-c9e7-456f-9277-6a71adf2a70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_terminal = torch.load(\n",
    "    r\"results\\ID-on-embeddings\\answerdotai\\ModernBERT-based\\0.001\\few\\seed549\\model\\model_epoch0002.tar\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d9f6b-f98d-4d18-bc75-7dcd61eb56eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(m_terminal[\"model_state_dict\"][\"individual_slopes.weight\"].detach().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4abdd-c475-478d-8649-9945fee24284",
   "metadata": {},
   "outputs": [],
   "source": [
    "[plt.hist(m_terminal[\"model_state_dict\"][\"individual_slopes.weight\"].detach().numpy()[i]) for i in range(0, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b15e0-44eb-4ce8-9f98-02dd530c5437",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = m_terminal(d, ids)\n",
    "anchor, positive, negative = torch.unbind(torch.reshape(logits, (-1, 3, embed_dim)), dim=1)\n",
    "tri_loss = ut.trinomial_loss(anchor, positive, negative, task, temperature, distance_metric)\n",
    "l1_pen_ID = md.l1_regularization(m_terminal, \"individual_slopes.weight\", \"few\").to(device) #L1-norm to enforce sparsity (many 0s)\n",
    "complexity_loss_ID = (lmbda/n_participants) * l1_pen_ID\n",
    "loss = tri_loss + complexity_loss_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194858b5-d459-4cee-bbe6-d14f4930714b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a6f0eb-1be2-488f-b9c4-54ba23222bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "[plt.hist(model_weight.individual_slopes(torch.LongTensor([id])).detach().numpy()[-1]) for id in range(0, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a598523b-5b91-4a6b-8d14-1506559fb960",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results\\ID-on-embeddings\\answerdotai\\ModernBERT-based\\0.001\\few\\seed549\\model\\model_epoch0002.tar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
